;
; ======== Hwi_asm.s62 ========
;
;! Revision History
;! ================
;! 18-May-2011 kw       reviewed and bc-merged family.c64p changes back into
;!                      this file and re-enabled 64x (SDOCM00081066)
;! 19-Mar-2007 cmcc     Moved ISTP initialization to Hwi.c
;! 04-Dec-2006 cmcc     Added isdefed for Hwi_plug cache calls
;! 23-Oct-2006 agd	Fixed cache management macros
;! 12-Sep-2006 cmcc     Added .sect and .clink to all functions
;! 24-Mar-2006 agd      Added switchToIsrStack and switchToTaskStack
;! 16-Aug-2005 agd      created
;

;        .cdecls C,NOLIST,"package/internal/Hwi.xdc.h" 

        .text

ISTPMASK  .set  0xfffffc00      ; mask off HPEINT and rsv bits of ISTP
MVK_OP    .set  0x2a            ; opcode for "MVK 0, B0" 
MVKH_OP   .set  0x6a            ; opcode for "MVKH 0, B0"

L1PIBAR .set    0x01844020      ; L1P invalidate base address register
L1DFBAR .set    0x01844030      ; L1D flush base address register

SP              .set    b15

;
;  ======== flushL1Dcache ========
;  Program the L1D Flush memory map register to flush the vector that is
;  currently being plugged.  This macro is used in C62_plug/C62_dispatchPlug.
;  This macro is a "NOP" for c6x0x and c67P chips.
;
flushL1Dcache .macro reg
        mvkl L1DFBAR, b0
        mvkh L1DFBAR, b0
        mvk 8, a0
||      stw :reg:, *b0++
        stw a0, *b0
        .endm

;
;  ======== invalidateL1Pcache ========
;  Program the L1P invalidate memory map register to invalidate the vector that
;  is currently being plugged. This macro is used in C62_plug/C62_dispatchPlug.
;  This macro is a "NOP" for c6x0x and c6x1x chips.
;  Note:  On c6x1x chips, L1P does not need to be invalidated since
;         the hardware will sync it up with what is in L2 after an
;         invalidate of L1D.
;
invalidateL1Pcache .macro reg
        mvkl L1PIBAR, b0        ; L1P invalidate vector being plugged.
        mvkh L1PIBAR, b0        ; only needed for 64, 64P, 67P but not 62/67.
        mvk 8, a0
||      stw :reg:, *b0++
        stw a0, *b0
        .endm

;
;  ======== waitOnCache ========
;  This macro spins waiting on completion of either L1D flush or L1P
;  invalidate.  In the case that we do both, it will wait for the
;  L1P invalidate.
;
waitOnCache .macro reg
waitinv:
        ldw *:reg:, b1
        nop 4
  [ b1] b waitinv               ; make sure the flush or invalidate completes.
        nop 5
        .endm

;
; ======== Hwi_plug ========
;! Plug an interrupt vector with an ISR address.
;!       a4 <- intNum
;!       b4 <- isr
;
        .sect ".text:_ti_sysbios_family_c64_Hwi_plug__E"
        .clink
        .global _ti_sysbios_family_c64_Hwi_plug__E
_ti_sysbios_family_c64_Hwi_plug__E:
        .asmfunc
        mvk     1, a2
        mvc     ier, b8         ; disable the interrupt currently being
||      shl     a2, a4, a2      ; plugged but leave global interrupts enabled.
        xor     -1, a2, b5
        and     b8, b5, b5
        mvc     b5, ier

        ; FORM DESTINATION ADDRESS OF ACTUAL FETCH PACKET
        mvc     istp, b5        ; interrupt vector table pointer
        mvkl    ISTPMASK, b0
        mvkh    ISTPMASK, b0
        and     b0, b5, b5      ; mask to get ISTP
        shl     a4, 5, b7       ; intNum << 5 (table increments of 0x20)
        add     b5, b7, b5      ; b5 = interrupt fetch packet start address
        mv      b5, a2          ; use ISTP as direct destination

        ; replace existing "mvkl isr, b0" instruction
        clr b4, 16, 31, b1      ; keep 16 lsb
        shl b1, 7, b1
        mvkl MVK_OP, b0
        mvkh MVK_OP, b0
        or b0, b1, b0
        stw b0,*a2[3]

        ; replace existing "mvkh isr, b0" instruction
        clr b4, 0, 15, b1       ; keep 16 msb
        shru b1, 9, b1
        mvkl MVKH_OP, b0
        mvkh MVKH_OP, b0
        or b0, b1, b0
        stw b0,*a2[4]


        .if !($isdefed("SIM_NO_CACHE"))  ; The sim6xxx can't handle cache macros

        flushL1Dcache b5        ; macro to flush L1D cache

        invalidateL1Pcache b5   ; macro to invalidate L1P cache

        waitOncache b0          ; macro to wait on completion of L1D or L1P
        
        .endif                  


        mvc     ier, b0
        or      b0, b8, b8      ; restore original mask OR'd with current ier.
        mvc     b8, ier

        b b3                    ; return to caller
        nop 5
        .endasmfunc
